# ✅ Install required packages
!pip install -q langchain google-generativeai

# ✅ Imports
import google.generativeai as genai
from langchain_core.language_models import LLM
from typing import List, Optional

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ✅ Configure your Gemini API key
genai.configure(api_key="YOUR_API_KEY_HERE")  # Replace with your actual key

# ✅ Gemini LLM wrapper for LangChain
class GeminiLLM(LLM):
    model_name: str = "models/gemini-1.5-pro-latest"
    temperature: float = 0.5

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        model = genai.GenerativeModel(self.model_name)
        chat = model.start_chat()
        response = chat.send_message(prompt)
        return response.text

    @property
    def _llm_type(self) -> str:
        return "google_gemini_custom"

# ✅ Prompt for resume analysis
template = """
You are an expert career coach. Analyze the following resume text and provide:
1. A brief summary
2. Strengths
3. Weaknesses
4. Suggestions for improvement

Resume:
{resume}
"""

prompt = PromptTemplate(input_variables=["resume"], template=template)

# ✅ LangChain chain
llm = GeminiLLM()
analyzer = LLMChain(llm=llm, prompt=prompt)

# ✅ Terminal-style loop for resume analysis
print("📄 Resume Analyzer (type 'exit' to stop) 👇\n")

while True:
    resume_text = input("Paste resume text: ")
    if resume_text.lower() in ["exit", "quit"]:
        print("👋 Goodbye!")
        break
    try:
        analysis = analyzer.run({"resume": resume_text})
        print("\n🧠 Analysis:\n", analysis.strip(), "\n")
    except Exception as e:
        print("⚠️ Error:", e)
