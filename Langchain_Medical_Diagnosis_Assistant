# ✅ Install required packages
!pip install -q langchain google-generativeai

# ✅ Import necessary modules
import google.generativeai as genai
from langchain_core.language_models import LLM
from typing import List, Optional

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ✅ Configure Gemini API key
genai.configure(api_key="YOUR_API_KEY_HERE")  # Replace with your actual API key

# ✅ Custom Gemini wrapper
class GeminiLLM(LLM):
    model_name: str = "models/gemini-1.5-pro-latest"
    temperature: float = 0.5

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        model = genai.GenerativeModel(self.model_name)
        chat = model.start_chat()
        response = chat.send_message(prompt)
        return response.text

    @property
    def _llm_type(self) -> str:
        return "google_gemini_custom"

# ✅ Prompt template for medical diagnosis
template = """
You are a helpful and experienced medical assistant (not a doctor).
Based on the symptoms provided, give:
1. A possible diagnosis (clearly state that it's not definitive)
2. Recommended next steps
3. Whether it's urgent or not

Symptoms:
{symptoms}
"""

prompt = PromptTemplate(input_variables=["symptoms"], template=template)

# ✅ Create LangChain chain
llm = GeminiLLM()
diagnosis_assistant = LLMChain(llm=llm, prompt=prompt)

# ✅ Terminal-style input loop
print("🩺 Medical Diagnosis Assistant (type 'exit' to stop) 👇\n")

while True:
    symptoms = input("Describe your symptoms: ")
    if symptoms.lower() in ["exit", "quit"]:
        print("👋 Stay healthy!")
        break
    try:
        response = diagnosis_assistant.run({"symptoms": symptoms})
        print("\n🧠 Response:\n", response.strip(), "\n")
    except Exception as e:
        print("⚠️ Error:", e)
