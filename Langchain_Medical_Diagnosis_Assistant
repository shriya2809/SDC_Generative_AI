# âœ… Install required packages
!pip install -q langchain google-generativeai

# âœ… Import necessary modules
import google.generativeai as genai
from langchain_core.language_models import LLM
from typing import List, Optional

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# âœ… Configure Gemini API key
genai.configure(api_key="YOUR_API_KEY_HERE")  # Replace with your actual API key

# âœ… Custom Gemini wrapper
class GeminiLLM(LLM):
    model_name: str = "models/gemini-1.5-pro-latest"
    temperature: float = 0.5

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        model = genai.GenerativeModel(self.model_name)
        chat = model.start_chat()
        response = chat.send_message(prompt)
        return response.text

    @property
    def _llm_type(self) -> str:
        return "google_gemini_custom"

# âœ… Prompt template for medical diagnosis
template = """
You are a helpful and experienced medical assistant (not a doctor).
Based on the symptoms provided, give:
1. A possible diagnosis (clearly state that it's not definitive)
2. Recommended next steps
3. Whether it's urgent or not

Symptoms:
{symptoms}
"""

prompt = PromptTemplate(input_variables=["symptoms"], template=template)

# âœ… Create LangChain chain
llm = GeminiLLM()
diagnosis_assistant = LLMChain(llm=llm, prompt=prompt)

# âœ… Terminal-style input loop
print("ğŸ©º Medical Diagnosis Assistant (type 'exit' to stop) ğŸ‘‡\n")

while True:
    symptoms = input("Describe your symptoms: ")
    if symptoms.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ Stay healthy!")
        break
    try:
        response = diagnosis_assistant.run({"symptoms": symptoms})
        print("\nğŸ§  Response:\n", response.strip(), "\n")
    except Exception as e:
        print("âš ï¸ Error:", e)
